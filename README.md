# Sign-Language-Recognition-with-Voice-enabled-using-Media-Pipe-KNN-Classifier
The project aims to bridge the communication gap between individuals who primarily use Sign Language. It specifically focuses on recognizing alphabets (letters Aâ€“Z) in real-time from live webcam feeds. By converting these recognized gestures into audible speech instantly, the system significantly enhances communication inclusivity. It employs
state-of-the-art computer vision techniques via MediaPipe for
landmark detection, integrates lightweight machine learning
models through K-Nearest Neighbors (KNN) for efficient
gesture classification, and utilizes both online and offline textto-speech (TTS) technologies to deliver immediate audio
feedback. The overall solution is designed for real-world
deployment, requiring minimal hardware and computational
resources.
